{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using FundamentalsNumericalComputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1\n",
    "\n",
    "## Floating-point numbers\n",
    "\n",
    "This [Section](https://tobydriscoll.net/fnc-julia/intro/floating-point.html) was primarily about issues that arise working with floating point numbers.  The main takeaways were:\n",
    "\n",
    "* Floating point numbers are approximations of real numbers. The consist of zero and all numbers of the form:\n",
    "\n",
    "$$\n",
    "\\pm (1 + f) \\times 2^n\n",
    "$$\n",
    "\n",
    "where $n$ is the exponent, and $1+f$ is the significand:\n",
    "\n",
    "$$\n",
    "f = \\sum_{i=1}^d \\frac{b_i}{2^i}, ~~~~~ b_i \\in \\{0,1\\}\n",
    "$$\n",
    "\n",
    "\n",
    "* Machine epsilon $\\epsilon_{\\text{mach}}$ is the smallest number that can be added to 1 and still be different from 1.\n",
    "\n",
    "* Double precision (IEEE 754) floating point numbers have 53 bits of precision, and so have $\\epsilon_{\\text{mach}} = 2^{-52} \\approx 2.2 \\times 10^{-16}$.\n",
    "\n",
    "* IEEE754 also includes NaN, -Inf and Inf. These are useful for handling errors and overflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises 1.1\n",
    "\n",
    "#### 1.1.1 \n",
    "\n",
    "Consider a floating point set with $d=4$.\n",
    "\n",
    "a) How many elements of F are there in the interval $[1/2,4]$ including the endpoints?\n",
    "\n",
    "Between each power of 2 there are 2^4 elements (including the first end point). So there are 2^4*3 + 1  = 49 elements in the interval.  \n",
    "\n",
    "b) What is element of F that is closest to $1/10$?\n",
    "\n",
    "The closest element must have n = -4 (as  2^-4 = 1/16 < 1/10 < 1/8 = 2^-3).  \n",
    "So we want (1+f)/16 = 1/10, or f = 0.6.  The hint suggests just enumerating all the candidates.  Since `0b0.1001` is .5625, and `0b0.1010` is .625, we see that the closest is `0.1010' or f=0.625. so that the final answers is 1.625*2^-4 =0.1015625.  \n",
    "\n",
    "c) What is the smallest positive integer not in F? \n",
    "Here we need to look for the value of the exponent for which the spacing between floating point numbers is greater than 1. The spacing is 2^-4*2^n. So we need to find the smallest n such that 2^-4*2^n > 1. This is n = 5. So the smallest positive integer not in F is 32+1=33. We can verify this  in Julia by using the floating point hex representation of floating point numbers. In this case we can write `0x1.0p5` which is 32, and then the next larger integer is `0x1.1p5` which is 34.  So 33 is not in F. \n",
    "Note that for n=4 the spacing is exactly 1, so the elements of F between 16 and 32 are exactly integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nextfloat(floatmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7976931348623157e308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nextfloat(-Inf64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats interesting. This say that Inf and -Inf sit 'one $\\epsilon$ away from the maximum values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems and conditioning\n",
    "\n",
    "This section discussed subtractive cancellation as a main source of error in numerical computations. It also introduced the concept of conditioning of a problem, which is a measure of how sensitive the solution is to small changes in the input data:\n",
    "\n",
    "Condition Number:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\kappa &= \\frac{\\text{relative change in output}}{\\text{relative change in input}} \\\\\n",
    "       &= \\frac{\\frac{\\Delta f}{f}}{\\frac{\\Delta x}{x}} \\\\\n",
    "       &= \\frac{|f(x)- f(x + \\epsilon x)| }{|\\epsilon f(x)| }\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If $f$ is differentiable:\n",
    "\n",
    "$$\n",
    "\\kappa = \\frac{|xf'(x)|}{|f(x)|}\n",
    "$$\n",
    "\n",
    "For example, the condition number of the function $f(x) = x + c$ is $\\frac{|x|}{|x + c|}$, which is large when $x$ is close to $-c$.  This is is the subtractive cancellation issue.  \n",
    "\n",
    "The condition number can be used to approximate the relative error in the output given the relative error in the input.\n",
    "\n",
    "For composite functions, the condition numbers muiltply. If $h(x) = f(g(x))$, then:\n",
    "\n",
    "$$\n",
    "\\kappa_h(x) = \\kappa_f (g(x)) \\times \\kappa_g(x)\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "\n",
    "This section was primarily an introduction to writing algorithms as code in Julia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "#### 1.3.1\n",
    "Write a julia function `poly1p` that evaluates a polynomial `p`.  at x = -1. You should do this directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function poly1(p)\n",
    "    n = length(p)\n",
    "    res = 0.0\n",
    "    for i in 1:n\n",
    "        res += p[i]*(-1)^(i-1)\n",
    "    end\n",
    "    res\n",
    "end\n",
    "\n",
    "poly1([1,-1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poly1([0,-1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2\n",
    "Compute sample variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "samplevar (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function samplevar(x)\n",
    "    n = length(x)\n",
    "    sum((x .- mean(x)).^2) / (n-1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.7755575615628914e-17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Statistics\n",
    "test = rand(200)\n",
    "var(test) - samplevar(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3877787807814457e-17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps(var(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know if it is cheating to use the built in sum and mean and broadcasting ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability\n",
    "\n",
    "This section defines an algorithm as \"unstable\" if the error exceeds what conditioning can explain. The example they give is of using the standard quadradic formula to find the roots of a quadradic polynomial. The standard formula are unstable because of the subtraction of two nearly equal numbers. However if instead you find the 'stable' root and then use the identity $x_1x_2 = c/a$ to find the other root, then you can avoid the subtraction and the algorithm is stable.\n",
    "\n",
    "This section also defines 'backward error' as the error in the input that would cause the computed result. This is a useful concept because it allows you to determine if the error is due to the algorithm or the input. If the backward error is small, then the algorithm is stable. If the backward error is large, then the algorithm is unstable.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "#### Exercise 1.4.2\n",
    "\n",
    "Let $f(x) = \\frac{e^x -1}{x}$\n",
    "\n",
    "a) find the condition number of $f$.  What is the maximum over $-1 \\leq x \\leq 1$?\n",
    "\n",
    "$$\n",
    "f'(x) = \\frac{e^x}{x} - \\frac{e^x - 1}{x^2} = \\frac{e^x(x-1) + 1}{x^2}\n",
    "$$\n",
    "\n",
    "So the condition number is:\n",
    "\n",
    "$$\n",
    "\\kappa = \\frac{e^x(x-1) + 1}{e^x-1} = x - 1 + \\frac{x}{e^x-1}\n",
    "$$\n",
    "\n",
    "The maximum is at $x=1$ and is about 0.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 1.0050167084167947\n",
       " 1.0005001667083846\n",
       " 1.000050001667141\n",
       " 1.000005000006965\n",
       " 1.0000004999621837\n",
       " 1.0000000494336803\n",
       " 0.999999993922529\n",
       " 1.000000082740371\n",
       " 1.000000082740371\n",
       " 1.000000082740371"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [10.0^-i for i in 2:11]\n",
    "obvious = (exp.(x) .- 1) ./ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 0.010000000000000002\n",
       " 0.001\n",
       " 0.0001\n",
       " 1.0e-5\n",
       " 1.0e-6\n",
       " 1.0000000000000001e-7\n",
       " 1.0e-8\n",
       " 1.0e-9\n",
       " 1.0e-10\n",
       " 1.0e-11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 1.0050167084168058\n",
       " 1.0005001667083417\n",
       " 1.0000500016667084\n",
       " 1.0000050000166667\n",
       " 1.0000005000001666\n",
       " 1.0000000500000017\n",
       " 1.000000005\n",
       " 1.0000000005\n",
       " 1.00000000005\n",
       " 1.000000000005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefficients = [1/factorial(i) for i in 1:8]\n",
    "f_mac(x) = Polynomial(coefficients)(x)\n",
    "series = [f_mac(xi) for xi in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       "  1.1046811613451617e-14\n",
       " -4.283318501737127e-14\n",
       " -4.325212636097066e-13\n",
       "  9.70174641418975e-12\n",
       "  3.798293112844667e-11\n",
       "  5.663214061968672e-10\n",
       "  1.1077471007857804e-8\n",
       " -8.224036415312194e-8\n",
       " -8.269036415312195e-8\n",
       " -8.273536415312195e-8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(series.-obvious)./obvious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the relative error increases... so what? We expect the series approximation to become more accurate with smaller x, so the increased relative error is not due to that. Is likely due instead to the increase in subtractive cancellation that occurs as exp(x) becomes closer to 1 (even though the condition number is decreasing!) this means the obvious algorthm for computing $(e^x-1)/x$ is unstable near 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
